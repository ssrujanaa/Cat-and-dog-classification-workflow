{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-21.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras==2.1.5\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n",
      "\u001b[K     |████████████████████████████████| 334 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow==1.13.1\n",
      "  Downloading tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 92.5 MB 113 kB/s  eta 0:00:01   |▉                               | 2.3 MB 3.0 MB/s eta 0:00:30     |█                               | 2.7 MB 3.0 MB/s eta 0:00:30     |██████▉                         | 19.6 MB 3.3 MB/s eta 0:00:22     |███████▍                        | 21.5 MB 9.6 MB/s eta 0:00:08     |████████▍                       | 24.3 MB 9.6 MB/s eta 0:00:08     |████████▌                       | 24.7 MB 9.6 MB/s eta 0:00:08     |███████████████████████▊        | 68.7 MB 7.5 MB/s eta 0:00:04     |█████████████████████████       | 72.1 MB 8.5 MB/s eta 0:00:03     |█████████████████████████▏      | 72.9 MB 8.5 MB/s eta 0:00:03     |█████████████████████████████▊  | 86.0 MB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 3.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 6.8 MB/s eta 0:00:01     |█████████████████▊              | 5.3 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.7.0-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 12.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 2.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting optkeras\n",
      "  Downloading optkeras-0.0.7-py3-none-any.whl (6.9 kB)\n",
      "Collecting h5py==2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 3.5 MB/s eta 0:00:012     |█████████████████▏              | 13.9 MB 4.4 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/lib64/python3.6/site-packages (from keras==2.1.5) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/lib/python3.6/site-packages (from keras==2.1.5) (1.14.0)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001b[K     |████████████████████████████████| 367 kB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.37.0-cp36-cp36m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.1.6\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 17.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.15.8-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 25.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2020.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 48 kB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.5.8-py2.py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cliff\n",
      "  Downloading cliff-3.7.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/site-packages (from optuna) (20.4)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.11-cp36-cp36m-manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib!=3.0.0,>=2.0.0\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 715 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock>=2.0.0\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.6/site-packages (from cliff->optuna) (2.4.7)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-1.5.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/site-packages (from sqlalchemy>=1.1.0->optuna) (1.7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting greenlet!=0.4.17; python_version >= \"3\"\n",
      "  Downloading greenlet-1.0.0-cp36-cp36m-manylinux2010_x86_64.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 14.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib64/python3.6/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/site-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/site-packages (from cmd2>=1.0.0->cliff->optuna) (20.1.0)\n",
      "Collecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.1.0)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pyperclip, since package 'wheel' is not installed.\n",
      "Installing collected packages: pip, numpy, scipy, keras, gast, keras-preprocessing, absl-py, mock, tensorflow-estimator, grpcio, h5py, keras-applications, termcolor, markdown, protobuf, wheel, werkzeug, tensorboard, astor, tensorflow, pandas, pillow, threadpoolctl, joblib, scikit-learn, sklearn, python-editor, greenlet, sqlalchemy, Mako, alembic, pbr, stevedore, PrettyTable, pyperclip, colorama, cmd2, cliff, cmaes, colorlog, tqdm, optuna, imageio, tifffile, networkx, kiwisolver, cycler, matplotlib, PyWavelets, scikit-image, optkeras\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.2\n",
      "    Uninstalling pip-20.2.2:\n",
      "      Successfully uninstalled pip-20.2.2\n",
      "    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for pyperclip ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Mako-1.1.4 PrettyTable-2.1.0 PyWavelets-1.1.1 absl-py-0.12.0 alembic-1.5.8 astor-0.8.1 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 cycler-0.10.0 gast-0.4.0 greenlet-1.0.0 grpcio-1.37.0 h5py-2.10.0 imageio-2.9.0 joblib-1.0.1 keras-2.1.5 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.4 matplotlib-3.3.4 mock-4.0.3 networkx-2.5.1 numpy-1.19.5 optkeras-0.0.7 optuna-2.7.0 pandas-1.1.5 pbr-5.5.1 pillow-8.2.0 pip-21.1 protobuf-3.15.8 pyperclip-1.8.2 python-editor-1.0.4 scikit-image-0.17.2 scikit-learn-0.24.1 scipy-1.5.4 sklearn-0.0 sqlalchemy-1.4.11 stevedore-3.3.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 tifffile-2020.9.3 tqdm-4.60.0 werkzeug-1.0.1 wheel-0.36.2\n"
     ]
    }
   ],
   "source": [
    "!sudo pip3 install --upgrade pip keras==2.1.5 tensorflow==1.13.1 numpy pandas pillow sklearn optuna scikit-image  optkeras h5py==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pegasus.api.workflow.Workflow at 0x7f8f56c22208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import requests \n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "#Import Pegasus API\n",
    "from Pegasus.api import *\n",
    "\n",
    "#Properties\n",
    "props = Properties()\n",
    "props[\"dagman.retry\"] = \"100\"\n",
    "props[\"pegasus.transfer.arguments\"] = \"-m 1\"\n",
    "props.write()\n",
    "\n",
    "#Replica Catalog\n",
    "rc = ReplicaCatalog()\n",
    "input_files = glob('*.jpg')\n",
    "input_files.sort()\n",
    "in_files=[]\n",
    "\n",
    "checkpoint_file = \"checkpoint_file2.hdf5\"\n",
    "if not os.path.isfile(checkpoint_file):\n",
    "    df = pd.DataFrame(list())\n",
    "    df.to_csv(checkpoint_file)\n",
    "    \n",
    "hpo_checkpoint_file = 'hpo_checkpoint.pkl'\n",
    "if not os.path.isfile(hpo_checkpoint_file):\n",
    "    df = pd.DataFrame(list())\n",
    "    df.to_csv(hpo_checkpoint_file)\n",
    "    \n",
    "for file in input_files:\n",
    "    in_files.append(File(file))\n",
    "    rc.add_replica(\"local\", File(file), str(Path(\".\").resolve() / file))  \n",
    "rc.add_replica(\"local\", checkpoint_file, Path(\".\").resolve() / checkpoint_file)\n",
    "rc.add_replica(\"local\", hpo_checkpoint_file, Path(\".\").resolve() / hpo_checkpoint_file)\n",
    "rc.write()\n",
    "\n",
    "\n",
    "#Transformation\n",
    "tools_container = Container(\n",
    "                    \"tools-container\", \n",
    "                    Container.DOCKER, \n",
    "                    image=\"docker:///ssrujanaa/catsanddogs:latest\"\n",
    "                )\n",
    "\n",
    "pre_process_resize = Transformation( \"preprocess1.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"/home/scitech/shared-data/CatsAndDogs/preprocess1.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "\n",
    "# pre_process_augment = Transformation( \"Augmentation.py\",\n",
    "#             site=\"condorpool\",\n",
    "#             pfn=\"/usr/bin/Augmentation.py\",\n",
    "#             is_stageable=True\n",
    "#             )\n",
    "\n",
    "data_split  = Transformation( \"Data_Split.py\",\n",
    "            site=\"local\",\n",
    "            pfn=\"/home/scitech/shared-data/CatsAndDogs/Data_Split.py\",\n",
    "            is_stageable=True\n",
    "            )\n",
    "\n",
    "\n",
    "# hpo  = Transformation( \"hpo_checkpointing.py\",\n",
    "#             site=\"condorpool\",\n",
    "#             pfn=\"/usr/bin/hpo_checkpointing.py\",\n",
    "#             is_stageable=False,\n",
    "#             container=tools_container\n",
    "#             )\n",
    "\n",
    "# vgg_model  = Transformation( \"VGG_model.py\",\n",
    "#             site=\"condorpool\",\n",
    "#             pfn=\"/usr/bin/VGG_model.py\",\n",
    "#             is_stageable=False,\n",
    "#             container=tools_container\n",
    "#             )\n",
    "\n",
    "# test_model =  Transformation( \"Test.py\",\n",
    "#             site=\"local\",\n",
    "#             pfn=\"/home/scitech/shared-data/CatsAndDogs/Test.py\",\n",
    "#             is_stageable=True\n",
    "#             )\n",
    "                    \n",
    "tc = TransformationCatalog()\\\n",
    "    .add_containers(tools_container)\\\n",
    "    .add_transformations(pre_process_resize,data_split)\\\n",
    "    .write()\n",
    "#     .add_transformations(pre_process_resize,pre_process_augment,data_split,hpo,vgg_model,test_model)\\\n",
    "#Workflow\n",
    "wf = Workflow(\"Cats_and_Dogs\", infer_dependencies=True)\n",
    "\n",
    "\n",
    "resized_images = File('resized_images.txt')\n",
    "all_files = [File(\"resized_{}\".format(f.lfn)) for f in in_files]\n",
    "labels = File('labels.txt')\n",
    "\n",
    "job_preprocess1 = Job(pre_process_resize)\\\n",
    "                    .add_inputs(*in_files)\\\n",
    "                    .add_outputs(*all_files,resized_images,labels) \n",
    "\n",
    "aug_images_txt = File('augmentation.txt')\n",
    "aug_labels_txt = File('aug_labels.txt')\n",
    "augmented_files = []\n",
    "for f in all_files:\n",
    "    augmented_files.extend([File(str(f).replace(\"{}\".format(os.path.splitext(str(f))[0]), \"Aug_{}_{}\".format(os.path.splitext(str(f))[0],i))) for i in range(3)])\n",
    "\n",
    "    \n",
    "job_preprocess2 = Job(pre_process_augment)\\\n",
    "                    .add_inputs(*all_files,labels)\\\n",
    "                    .add_outputs(aug_images_txt,aug_labels_txt,*augmented_files)\n",
    "\n",
    "training_data = File('training.pkl')\n",
    "testing_data = File('testing.pkl')\n",
    "val_data = File('validation.pkl')\n",
    "\n",
    "# job_data_split = Job(data_split)\\\n",
    "#                     .add_inputs(*augmented_files,labels)\\\n",
    "#                     .add_outputs(training_data,testing_data,val_data)\n",
    "job_data_split = Job(data_split)\\\n",
    "                    .add_inputs(*all_files,labels)\\\n",
    "                    .add_outputs(training_data,testing_data,val_data)\n",
    "\n",
    "model = File('model.h5')\n",
    "output_file = File('hpo_results.pkl')\n",
    "job_hpo = Job(hpo)\\\n",
    "                    .add_checkpoint(File(hpo_checkpoint_file), stage_out=True)\\\n",
    "                    .add_inputs(*augmented_files,training_data,testing_data,val_data)\\\n",
    "                    .add_profiles(Namespace.PEGASUS, key=\"maxwalltime\", value=1)\\\n",
    "                    .add_outputs(output_file)\n",
    "\n",
    "job_vgg_model = Job(vgg_model)\\\n",
    "                    .add_args(\"-epochs\",6, \"--batch_size\",2)\\\n",
    "                    .add_checkpoint(File(checkpoint_file), stage_out=True)\\\n",
    "                    .add_inputs(*augmented_files,training_data,testing_data,val_data,output_file)\\\n",
    "                    .add_profiles(Namespace.PEGASUS, key=\"maxwalltime\", value=1)\\\n",
    "                    .add_outputs(model)\n",
    "\n",
    "results_file = File('Result_Metrics.txt')\n",
    "job_test_model = Job(test_model)\\\n",
    "                    .add_inputs(*augmented_files,testing_data,model)\\\n",
    "                    .add_outputs(results_file)\n",
    "\n",
    "# wf.add_jobs(job_preprocess1,job_preprocess2,job_data_split,job_hpo,job_vgg_model,job_test_model)  \n",
    "wf.add_jobs(job_preprocess1,job_data_split)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "################\n",
      "# pegasus-plan #\n",
      "################\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword $defs - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword additionalItems - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "[main] WARN  schema.JsonMetaSchema  - Unknown keyword examples - you should define your own Meta Schema. If the keyword is irrelevant for validation, just use a NonValidationKeyword\n",
      "2021.04.16 19:23:24.127 UTC:\n",
      "2021.04.16 19:23:24.133 UTC:   -----------------------------------------------------------------------\n",
      "2021.04.16 19:23:24.138 UTC:   File for submitting this DAG to HTCondor           : Cats_and_Dogs-0.dag.condor.sub\n",
      "2021.04.16 19:23:24.144 UTC:   Log of DAGMan debugging messages                 : Cats_and_Dogs-0.dag.dagman.out\n",
      "2021.04.16 19:23:24.152 UTC:   Log of HTCondor library output                     : Cats_and_Dogs-0.dag.lib.out\n",
      "2021.04.16 19:23:24.157 UTC:   Log of HTCondor library error messages             : Cats_and_Dogs-0.dag.lib.err\n",
      "2021.04.16 19:23:24.163 UTC:   Log of the life of condor_dagman itself          : Cats_and_Dogs-0.dag.dagman.log\n",
      "2021.04.16 19:23:24.168 UTC:\n",
      "2021.04.16 19:23:24.174 UTC:   -no_submit given, not submitting DAG to HTCondor.  You can do this with:\n",
      "2021.04.16 19:23:24.185 UTC:   -----------------------------------------------------------------------\n",
      "2021.04.16 19:23:25.188 UTC:   Your database is compatible with Pegasus version: 5.0.0dev\n",
      "2021.04.16 19:23:26.830 UTC:   Created Pegasus database in: sqlite:////home/scitech/shared-data/CatsAndDogs2/scitech/pegasus/Cats_and_Dogs/run0005/Cats_and_Dogs-0.replicas.db\n",
      "2021.04.16 19:23:26.837 UTC:   Your database is compatible with Pegasus version: 5.0.0dev\n",
      "2021.04.16 19:23:26.880 UTC:   Output replica catalog set to jdbc:sqlite:/home/scitech/shared-data/CatsAndDogs2/scitech/pegasus/Cats_and_Dogs/run0005/Cats_and_Dogs-0.replicas.db\n",
      "2021.04.16 19:23:27.149 UTC:   Submitting to condor Cats_and_Dogs-0.dag.condor.sub\n",
      "2021.04.16 19:23:27.390 UTC:\n",
      "2021.04.16 19:23:27.396 UTC:   Your workflow has been started and is running in the base directory:\n",
      "2021.04.16 19:23:27.405 UTC:\n",
      "2021.04.16 19:23:27.412 UTC:   /home/scitech/shared-data/CatsAndDogs2/scitech/pegasus/Cats_and_Dogs/run0005\n",
      "2021.04.16 19:23:27.417 UTC:\n",
      "2021.04.16 19:23:27.423 UTC:   *** To monitor the workflow you can run ***\n",
      "2021.04.16 19:23:27.428 UTC:\n",
      "2021.04.16 19:23:27.434 UTC:   pegasus-status -l /home/scitech/shared-data/CatsAndDogs2/scitech/pegasus/Cats_and_Dogs/run0005\n",
      "2021.04.16 19:23:27.439 UTC:\n",
      "2021.04.16 19:23:27.445 UTC:   *** To remove your workflow run ***\n",
      "2021.04.16 19:23:27.450 UTC:\n",
      "2021.04.16 19:23:27.456 UTC:   pegasus-remove /home/scitech/shared-data/CatsAndDogs2/scitech/pegasus/Cats_and_Dogs/run0005\n",
      "2021.04.16 19:23:27.750 UTC:   Time taken to execute is 5.9 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;32m#######\u001b[0m-------------------------------------------]  14.3% ..Running (\u001b[1;32mCompleted: 2\u001b[0m, \u001b[1;33mQueued: 0\u001b[0m, \u001b[1;36mRunning: 0\u001b[0m, \u001b[1;31mFailed: 0\u001b[0m)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-466fc3ff2ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m      \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/workflow.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/workflow.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/api/workflow.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, delay)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \"\"\"\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_chained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pegasus/dist/pegasus-5.0.0dev/lib64/python3.6/site-packages/Pegasus/client/_client.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, root_wf_name, submit_dir, delay)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "     wf.plan(submit=True)\\\n",
    "        .wait()\\\n",
    "        .analyze()\\\n",
    "        .statistics()\n",
    "except PegasusClientError as e:\n",
    "    print(e.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
