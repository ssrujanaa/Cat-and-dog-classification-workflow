{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "resized_images = get_data()\n",
    "cat_images=[]\n",
    "dog_images=[]\n",
    "labels=[] \n",
    "q = []\n",
    "for i in range(len(resized_images)):\n",
    "    if 'resized_Cat' in resized_images[i]:\n",
    "        cat_images.append(resized_images[i])\n",
    "    else:\n",
    "        dog_images.append(resized_images[i])\n",
    "\n",
    "datagen = ImageDataGenerator( rescale=1./255,\n",
    "            rotation_range = 40,  \n",
    "            horizontal_flip = True, \n",
    "            brightness_range = (0.5, 1.5)) \n",
    "\n",
    "for image in cat_images:\n",
    "    num = 1.0\n",
    "    img = load_img(image)  \n",
    "    x = img_to_array(img) \n",
    "    x = x.reshape((1, ) + x.shape) \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size = 1,\n",
    "                              save_to_dir = os.getcwd(),  \n",
    "                              save_prefix ='Aug_' + os.path.splitext(image.split('_')[1])[0] , save_format ='jpg'): \n",
    "        i += 1\n",
    "        labels.append(num)\n",
    "        if i > 2: \n",
    "            break\n",
    "for image in dog_images:\n",
    "        num = 0.0\n",
    "        img = load_img(image)  \n",
    "        x = img_to_array(img) \n",
    "        x = x.reshape((1, ) + x.shape)  \n",
    "        # Generating and saving 5 augmented samples  \n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size = 1,\n",
    "                                  save_to_dir = os.getcwd(),  \n",
    "                                  save_prefix= 'Aug_' + os.path.splitext(image.split('_')[1])[0] , save_format ='jpg'): \n",
    "            i += 1\n",
    "            labels.append(num)\n",
    "            if i > 2: \n",
    "                break\n",
    "                \n",
    "aug_cat = glob('Aug_Cat*.jpg')\n",
    "aug_dog = glob('Aug_Dog*.jpg')\n",
    "aug_images = aug_cat + aug_dog\n",
    "aug_cat.sort()\n",
    "for n in range(len(cat_images)):\n",
    "    k = 0\n",
    "    for m in range(len(aug_cat)):\n",
    "        if os.path.splitext(cat_images[n].split('_')[1])[0]  in aug_cat[m]:\n",
    "            photo = load_img(aug_cat[m])\n",
    "            photo.save('Aug_'+ os.path.splitext(cat_images[n].split('_')[1])[0] + '_' + str(k) +'.jpg', 'JPEG', quality=90)\n",
    "            q.append('Aug_'+ os.path.splitext(cat_images[n].split('_')[1])[0] + '_' +str(k) +'.jpg')\n",
    "            k+=1\n",
    "\n",
    "aug_dog.sort()\n",
    "for n in range(len(dog_images)):\n",
    "    k = 0\n",
    "    for m in range(len(aug_dog)):\n",
    "        if os.path.splitext(dog_images[n].split('_')[1])[0]  in aug_dog[m]:\n",
    "            photo = load_img(aug_dog[m])\n",
    "            photo.save('Aug_'+ os.path.splitext(dog_images[n].split('_')[1])[0] + '_' + str(k) + '.jpg', 'JPEG', quality=90)\n",
    "            q.append('Aug_'+ os.path.splitext(dog_images[n].split('_')[1])[0] + '_' + str(k) +'.jpg')\n",
    "            k+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_cat = glob('Aug_Cat*.jpg')\n",
    "aug_dog = glob('Aug_Dog*.jpg')\n",
    "aug_images = aug_cat + aug_dog\n",
    "aug_cat.sort()\n",
    "for n in range(len(cat_images)):\n",
    "    k = 0\n",
    "    for m in range(len(aug_cat)):\n",
    "        if os.path.splitext(cat_images[n])[0] in aug_cat[m]:\n",
    "            photo = load_img(aug_cat[m])\n",
    "            photo.save('Aug_'+ os.path.splitext(cat_images[n].split('_')[1])[0] +'.jpg', 'JPEG', quality=90)\n",
    "            q.append('Aug_'+ os.path.splitext(cat_images[n].split('_')[1])[0] + '.jpg')\n",
    "            k+=1\n",
    "\n",
    "aug_dog.sort()\n",
    "for n in range(len(dog_images)):\n",
    "    k = 0\n",
    "    for m in range(len(aug_dog)):\n",
    "        if os.path.splitext(dog_images[n])[0] in aug_dog[m]:\n",
    "            photo = load_img(aug_dog[m])\n",
    "            photo.save('Aug_'+ os.path.splitext(dog_images[n].split('_')[1])[0] + '.jpg', 'JPEG', quality=90)\n",
    "            q.append('Aug_'+ os.path.splitext(dog_images[n].split('_')[1])[0] + '.jpg')\n",
    "            k+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "from keras.preprocessing.image import ImageDataGenerator,  array_to_img, img_to_array, load_img \n",
    "from glob import glob\n",
    "from numpy import save\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def augment():\n",
    "    resized_images = glob('resized_*.jpg')\n",
    "    cat_images=[]\n",
    "    dog_images=[]\n",
    "    labels=[] \n",
    "    q = []\n",
    "    for i in range(len(resized_images)):\n",
    "        if 'resized_Cat' in resized_images[i]:\n",
    "            cat_images.append(resized_images[i])\n",
    "        else:\n",
    "            dog_images.append(resized_images[i])\n",
    "\n",
    "    datagen = ImageDataGenerator( rescale=1./255,\n",
    "                rotation_range = 40,  \n",
    "                horizontal_flip = True, \n",
    "                brightness_range = (0.5, 1.5)) \n",
    "\n",
    "    for image in cat_images:\n",
    "        num = 1.0\n",
    "        img = load_img(image)  \n",
    "        x = img_to_array(img) \n",
    "        x = x.reshape((1, ) + x.shape) \n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size = 1,\n",
    "                                  save_to_dir = os.getcwd(),  \n",
    "                                  save_prefix ='Aug_' + os.path.splitext(image.split('_')[1])[0] , save_format ='jpg'): \n",
    "            i += 1\n",
    "            labels.append(num)\n",
    "            if i > 2: \n",
    "                break\n",
    "    for image in dog_images:\n",
    "            num = 0.0\n",
    "            img = load_img(image)  \n",
    "            x = img_to_array(img) \n",
    "            x = x.reshape((1, ) + x.shape)  \n",
    "            # Generating and saving 5 augmented samples  \n",
    "            i = 0\n",
    "            for batch in datagen.flow(x, batch_size = 1,\n",
    "                                      save_to_dir = os.getcwd(),  \n",
    "                                      save_prefix= 'Aug_' + os.path.splitext(image.split('_')[1])[0] , save_format ='jpg'): \n",
    "                i += 1\n",
    "                labels.append(num)\n",
    "                if i > 2: \n",
    "                    break\n",
    "    return cat_images, dog_images,q,labels\n",
    "\n",
    "def rename_augmented_files():\n",
    "    cat_images, dog_images,q,labels = augment()\n",
    "    aug_cat = glob('Aug_Cat*.jpg')\n",
    "    aug_dog = glob('Aug_Dog*.jpg')\n",
    "    aug_images = aug_cat + aug_dog\n",
    "    aug_cat.sort()\n",
    "    for n in range(len(cat_images)):\n",
    "        k = 0\n",
    "        for m in range(len(aug_cat)):\n",
    "            if os.path.splitext(cat_images[n].split('_')[1])[0]  in aug_cat[m]:\n",
    "                photo = load_img(aug_cat[m])\n",
    "                photo.save('Aug_'+ os.path.splitext(cat_images[n].split('_')[1])[0] + '_' + str(k) +'.jpg', 'JPEG', quality=90)\n",
    "                q.append('Aug_'+ os.path.splitext(cat_images[n].split('_')[1])[0] + '_' +str(k) +'.jpg')\n",
    "                k+=1\n",
    "\n",
    "    aug_dog.sort()\n",
    "    for n in range(len(dog_images)):\n",
    "        k = 0\n",
    "        for m in range(len(aug_dog)):\n",
    "            if os.path.splitext(dog_images[n].split('_')[1])[0]  in aug_dog[m]:\n",
    "                photo = load_img(aug_dog[m])\n",
    "                photo.save('Aug_'+ os.path.splitext(dog_images[n].split('_')[1])[0] + '_' + str(k) + '.jpg', 'JPEG', quality=90)\n",
    "                q.append('Aug_'+ os.path.splitext(dog_images[n].split('_')[1])[0] + '_' + str(k) +'.jpg')\n",
    "                k+=1 \n",
    "def main():\n",
    "    rename_augmented_files()\n",
    "    return 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_filenames(filenames):\n",
    "\n",
    "    random.shuffle(filenames)\n",
    "    train, validate, test = np.split(filenames, [int(len(filenames)*0.7), int(len(filenames)*0.8)])\n",
    "    files_split_dict = {}\n",
    "    files_split_dict[\"train\"] = train\n",
    "    files_split_dict[\"test\"] = test\n",
    "    files_split_dict[\"validate\"] = validate\n",
    "    \n",
    "    train_filenames = [\"train_\" + file for file in train] \n",
    "    val_filenames = [\"val_\" + file for file in validate] \n",
    "    test_filenames =  [\"test_\" + file for file in test] \n",
    "    return train_filenames,val_filenames,test_filenames, files_split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 8\n",
    "workers_ids = [x for x in range(NUM_WORKERS)]\n",
    "random.shuffle(workers_ids)\n",
    "train, validate, test = np.split(workers_ids, [int(len(workers_ids)*0.7), int(len(workers_ids)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_split_dict = {}\n",
    "files_split_dict[\"train\"] = train\n",
    "files_split_dict[\"test\"] = test\n",
    "files_split_dict[\"validate\"] = validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess1_jobs_train = [Job(preprocess_tc1) for i in range(num_train_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:83: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "42/42 [==============================] - 9s 221ms/step - loss: 5.8602 - acc: 0.5238 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: saving model to checkpoint_file.hdf5\n",
      "Train on 42 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "16/42 [==========>...................] - ETA: 3s - loss: 8.0590 - acc: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-199089980b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-199089980b6d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             model.fit(x=train_photos, y=train_labels,batch_size=BATCH_SIZE , epochs=1, \n\u001b[0;32m--> 129\u001b[0;31m                            verbose=1,validation_data=(val_photos,val_labels), callbacks = [checkpoint])\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_weights_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m#saving the number of finished epochs to the same hdf5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "import pickle\n",
    "import signal\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input,Dense,BatchNormalization,Flatten,Dropout,GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import traceback\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model,load_model\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import sys\n",
    "import joblib\n",
    "import argparse\n",
    "import keras\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser(description='Cat and Dog image classification using Keras')\n",
    "    parser.add_argument('-epochs',  metavar='num_epochs', type=int, default = 5, help = \"Number of training epochs\")\n",
    "    parser.add_argument('--batch_size',  metavar='batch_size', type=int, default = 16, help = \"Batch Size\")\n",
    "    parser.add_argument('-f')\n",
    "    return parser.parse_args()\n",
    "\n",
    "#get training, testing and validation data from the saved pickle files.\n",
    "def get_data(train_data,val_data):\n",
    "    train_photos, train_labels = list(), list()\n",
    "    tp = list()\n",
    "    for file in train_data:\n",
    "        if 'Cat' in file:\n",
    "            output = 1.0\n",
    "        else:\n",
    "            output = 0.0\n",
    "        photo = load_img(file)\n",
    "        photo = img_to_array(photo)\n",
    "        train_photos.append(photo)\n",
    "        train_labels.append(output)\n",
    "    train_photos = asarray(train_photos)\n",
    "    train_labels = asarray(train_labels)\n",
    "\n",
    "    val_photos, val_labels = list(), list()\n",
    "    for file in val_data:\n",
    "        if 'Cat' in file:\n",
    "            output = 1.0\n",
    "        else:\n",
    "            output = 0.0\n",
    "        photo = load_img(file)\n",
    "        photo = img_to_array(photo)\n",
    "        val_photos.append(photo)\n",
    "        val_labels.append(output)\n",
    "    val_photos = asarray(val_photos)\n",
    "    val_labels = asarray(val_labels)\n",
    "    \n",
    "    return train_photos,train_labels,val_photos,val_labels\n",
    "\n",
    "#Definition of the VGG16 model and changing the output layer according to our requirements.\n",
    "#i.e., 2 output classes\n",
    "def get_model():\n",
    "    nb_classes = 2\n",
    "    Study = joblib.load('hpo_results.pkl')\n",
    "    _dict = Study.best_trial.params\n",
    "    activation_optuna = _dict['activation']\n",
    "    optimizer_optuna = _dict['optimizer']\n",
    "    \n",
    "    vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    x = vgg16_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(nb_classes, activation = activation_optuna)(x)\n",
    "    model = Model(input = vgg16_model.input, output = predictions)\n",
    "\n",
    "    for layer in vgg16_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer = optimizer_optuna,loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model,optimizer_optuna\n",
    "\n",
    "\n",
    "def main():\n",
    "    aug_cat = glob('aug_Cat*.jpg')\n",
    "    aug_dog = glob('aug_Dog*.jpg')\n",
    "    train_data = aug_cat + aug_dog\n",
    "    val_data = glob('resized_*.jpg')\n",
    "    train_photos,train_labels,val_photos,val_labels = get_data(train_data, val_data)\n",
    "    model,optimizer_optuna = get_model()\n",
    "    \n",
    "    #checkpoint file that saves the weights after each epoch - weights are overwritten to the same file\n",
    "    checkpoint_file = 'checkpoint_file.hdf5'\n",
    "    checkpoint = ModelCheckpoint(checkpoint_file, monitor='loss', verbose=1, mode='auto',save_weights_only = True, period=1)\n",
    "    \n",
    "    train_from_beginning = False\n",
    "    try:\n",
    "        #Since our hdf5 file contains additional data = epochs, skip_mismatch is used to avoid that column\n",
    "        model.load_weights(\"checkpoint_file.hdf5\",skip_mismatch=True)\n",
    "        with h5py.File('checkpoint_file.hdf5', \"r+\") as file:\n",
    "            data = file.get('epochs')[...].tolist()\n",
    "            \n",
    "        #loading the number of epochs already performed to resume training from that epoch\n",
    "        initial_epoch = data\n",
    "        model.compile(optimizer = optimizer_optuna,loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "        for i in range(initial_epoch,EPOCHS):\n",
    "            model.fit(x=train_photos, y=train_labels,batch_size=BATCH_SIZE , epochs=1, verbose=1,\n",
    "                      validation_data=(val_photos,val_labels), callbacks = [checkpoint])\n",
    "            checkpoint = ModelCheckpoint(checkpoint_file, monitor='loss', verbose=1, mode='auto',\n",
    "                                         save_weights_only = True, period=1)\n",
    "            \n",
    "            #saving the number of finished epochs to the same hdf5 file\n",
    "            with h5py.File('checkpoint_file.hdf5', \"a\") as file:\n",
    "                file['epochs'] = i\n",
    "    except OSError:\n",
    "        train_from_beginning = True\n",
    "\n",
    "    if train_from_beginning:\n",
    "        model.compile(optimizer = 'rmsprop',loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "        for i in range(EPOCHS):\n",
    "            model.fit(x=train_photos, y=train_labels,batch_size=BATCH_SIZE , epochs=1, \n",
    "                           verbose=1,validation_data=(val_photos,val_labels), callbacks = [checkpoint])\n",
    "            checkpoint = ModelCheckpoint(checkpoint_file, monitor='loss', verbose=1, mode='auto',save_weights_only = True, period=1)\n",
    "            #saving the number of finished epochs to the same hdf5 file\n",
    "            with h5py.File('checkpoint_file.hdf5', \"a\") as file:\n",
    "                file['epochs']=i\n",
    "\n",
    "    model.save('model.h5')\n",
    "    return 0\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    global EPOCHS\n",
    "    global BATCH_SIZE\n",
    "    args = parse_args(sys.argv[1:])\n",
    "    EPOCHS = args.epochs\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
